{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696175c9-278e-4ec3-96ae-d819f44cf808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T00:49:37.360397Z",
     "iopub.status.busy": "2023-04-22T00:49:37.359399Z",
     "iopub.status.idle": "2023-04-22T00:49:52.335724Z",
     "shell.execute_reply": "2023-04-22T00:49:52.334727Z",
     "shell.execute_reply.started": "2023-04-22T00:49:37.359399Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: 2023-04-22 03:49:52\n"
     ]
    }
   ],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebf155c-867c-40c5-9716-b1fd62173d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T00:49:52.337724Z",
     "iopub.status.busy": "2023-04-22T00:49:52.337724Z",
     "iopub.status.idle": "2023-04-22T00:50:07.020923Z",
     "shell.execute_reply": "2023-04-22T00:50:07.019925Z",
     "shell.execute_reply.started": "2023-04-22T00:49:52.337724Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark_Tutorial</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2c549ab1490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('PySpark_Tutorial')\\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901653ec-836d-4360-8f1a-b74493993df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T05:11:04.935403Z",
     "iopub.status.busy": "2023-04-22T05:11:04.935403Z",
     "iopub.status.idle": "2023-04-22T05:11:04.943324Z",
     "shell.execute_reply": "2023-04-22T05:11:04.943324Z",
     "shell.execute_reply.started": "2023-04-22T05:11:04.935403Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\Mamed\\YandexDisk\\_Documents\\Проекты\\2ГИС 2023\\10 городов\\Мастер_таблица_2ГИС_10_городов_230419_1700_ext.xlsx\"\n",
    "city = 'ten_city'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6946b94f-a40f-45dd-8c4e-ef288fed8559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T05:11:05.275833Z",
     "iopub.status.busy": "2023-04-22T05:11:05.275833Z",
     "iopub.status.idle": "2023-04-22T05:30:32.464878Z",
     "shell.execute_reply": "2023-04-22T05:30:32.464878Z",
     "shell.execute_reply.started": "2023-04-22T05:11:05.275833Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files/ten_city/ten_city_shars_230422_0811.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [19:27<00:00, 11.67s/it]\n"
     ]
    }
   ],
   "source": [
    "plot_matrix(file, city, cnt_graphics=100, cnt_shars=12, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e470d-9584-4939-93e1-951ca8b50863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3ab38cf5-600e-4216-83b1-b79571cd3218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T14:11:40.598789Z",
     "iopub.status.busy": "2023-04-22T14:11:40.598789Z",
     "iopub.status.idle": "2023-04-22T14:11:41.873220Z",
     "shell.execute_reply": "2023-04-22T14:11:41.872215Z",
     "shell.execute_reply.started": "2023-04-22T14:11:40.598789Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_tx_grouped_filtered = spark.read.parquet(f\"files/ten_city/df_tx_grouped_filtered_ten_city\")\n",
    "df_tx_grouped_filtered.createOrReplaceTempView('df_tx_grouped_filtered')\n",
    "rubrics = spark.sql('''select distinct rubricName from df_tx_grouped_filtered''').collect()\n",
    "rubrics = [i.asDict()['rubricName'] for i in rubrics]\n",
    "rubrics = '(\"' + '\",\"'.join(rubrics) + '\")'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9d91c0-3f65-4892-a4b8-14f28e8c4516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T05:35:39.831554Z",
     "iopub.status.busy": "2023-04-22T05:35:39.831554Z",
     "iopub.status.idle": "2023-04-22T07:12:16.275203Z",
     "shell.execute_reply": "2023-04-22T07:12:16.275203Z",
     "shell.execute_reply.started": "2023-04-22T05:35:39.831554Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [1:36:36<00:00, 144.90s/it]\n"
     ]
    }
   ],
   "source": [
    "df_schema = StructType([StructField('user', StringType(), True), StructField('proj', StringType(), True), StructField('rubricName', StringType(), True), StructField('rubricID', IntegerType(), True), StructField('time', StringType(), True), StructField('date', StringType(), True), StructField('org', StringType(), True), StructField('branch', StringType(), True), StructField('prod', StringType(), True), StructField('tx', StringType(), True), StructField('fl', StringType(), True), StructField('devmod', StringType(), True), StructField('lat', StringType(), True), StructField('lon', StringType(), True)])\n",
    "spark.read.option(\"header\",\"true\").csv(files_list_chain[0], schema=df_schema).where('1=0').write.mode('overwrite').parquet(f'files/ten_city/requests_for_shars')\n",
    "\n",
    "for file in tqdm(files_list_chain):\n",
    "    city = file.split('\\\\')[2]\n",
    "    final_df = spark.read.option(\"header\",\"true\").csv(file, schema=df_schema)\n",
    "    final_df.createOrReplaceTempView('df')\n",
    "    final_df = spark.sql(f'''\n",
    "        select rubricName, year(time) as year_r, \"{city}\" as city, count(*) cnt_requests\n",
    "        from df\n",
    "        where rubricName in {rubrics}\n",
    "        group by rubricName, year(time), \"{city}\"\n",
    "    ''')\n",
    "    \n",
    "    final_df.write.mode('append').parquet(f'files/ten_city/requests_for_shars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f4cde611-90ac-45b4-ae9b-9a56decfa077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T14:16:35.938545Z",
     "iopub.status.busy": "2023-04-22T14:16:35.938545Z",
     "iopub.status.idle": "2023-04-22T14:16:35.966052Z",
     "shell.execute_reply": "2023-04-22T14:16:35.965050Z",
     "shell.execute_reply.started": "2023-04-22T14:16:35.938545Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_matrix_cities(cnt_graphics=100, show=False):\n",
    "    city='ten_city'\n",
    "    shar_nums = list(range(1,16))*500\n",
    "    time = str(datetime.datetime.now())[2:16].replace('-','').replace(' ','_').replace(':','')\n",
    "    print(f'files/{city}/{city}_shars_{time}.docx')\n",
    "    df_src = spark.read.parquet(f'files/ten_city/requests_for_shars').toPandas()\n",
    "    df_new = df_src[['rubricName','city']].drop_duplicates().set_index(['rubricName','city'])\n",
    "    df_new['Запросы 2020'] = df_src[df_src['year_r'] == 2020].groupby(['rubricName', 'city']).sum('cnt_requests')[['cnt_requests']]\n",
    "    df_new['Запросы 2021'] = df_src[df_src['year_r'] == 2021].groupby(['rubricName', 'city']).sum('cnt_requests')[['cnt_requests']]\n",
    "    df_new['Запросы 2022'] = df_src[df_src['year_r'] == 2022].groupby(['rubricName', 'city']).sum('cnt_requests')[['cnt_requests']]\n",
    "    df_new['Запросы 2023'] = df_src[df_src['year_r'] == 2023].groupby(['rubricName', 'city']).sum('cnt_requests')[['cnt_requests']]\n",
    "    df_new = df_new.fillna(0).astype(int)\n",
    "    df_new['Запросы, итого'] =  df_new['Запросы 2020'] + df_new['Запросы 2021'] + df_new['Запросы 2022'] + df_new['Запросы 2023']\n",
    "    df_new = df_new.reset_index().set_index('city')\n",
    "\n",
    "    df_tx_grouped_filtered = spark.read.parquet(f\"files/ten_city/df_tx_grouped_filtered_ten_city\")\n",
    "    df_tx_grouped_filtered.createOrReplaceTempView('df_tx_grouped_filtered')\n",
    "    rubrics = spark.sql('''select distinct rubricName from df_tx_grouped_filtered''').collect()\n",
    "    rubrics = [i.asDict()['rubricName'] for i in rubrics]\n",
    "    \n",
    "    for rubric in tqdm(rubrics[:cnt_graphics]):\n",
    "        shar_num = shar_nums.pop()\n",
    "        df = df_new.loc[df_new['rubricName']==rubric]\n",
    "        df['Запросы, итого'] = (df['Запросы, итого'] - min(df['Запросы, итого'])) / (max(df['Запросы, итого']) - min(df['Запросы, итого']))*300\n",
    "        requests_total = df_new['Запросы 2023'].sum()\n",
    "        df['Рост/Падение, %'] = df['Запросы 2023'] / df['Запросы 2022']\n",
    "        df['Доля рынка, %'] = df['Запросы 2023'] / requests_total\n",
    "        x = (df['Доля рынка, %'])\n",
    "        y = (df['Рост/Падение, %'])\n",
    "        sizes = (df['Запросы, итого']/1000)\n",
    "        x_avg = (x.min()+x.max())/2\n",
    "        y_avg = (y.min()+y.max())/2\n",
    "        xi, yi = df['Доля рынка, %'], df['Рост/Падение, %']\n",
    "        df.loc[(xi > x_avg) & (yi > y_avg), 'group'] = 'Звёзды:'\n",
    "        df.loc[(xi > x_avg)  & (yi <= y_avg), 'group'] = 'Коровы:'\n",
    "        df.loc[(xi <= x_avg)  & (yi > y_avg), 'group'] = 'Дети:'\n",
    "        df.loc[(xi <= x_avg)  & (yi <= y_avg), 'group'] = 'Собаки:'\n",
    "        df = df.sort_values(['Доля рынка, %', 'Рост/Падение, %'], ascending=[False, False])\n",
    "\n",
    "        plt.rcParams['figure.figsize'] = 6.89*4, 4.25*4\n",
    "        plt.rcParams['figure.dpi'] = 2**8\n",
    "        plt.rcParams['font.size'] = '18'\n",
    "        fpath = Path(mpl.get_data_path(), r\"C:\\Users\\Mamed\\YandexDisk\\_Documents\\Проекты\\2ГИС 2023\\Лого\\arialnarrow.ttf\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(x, y, sizes, c='#C0504D', alpha=0.7)\n",
    "\n",
    "        n = 0.02\n",
    "        m = 0.02\n",
    "        ax.set_ylim(ax.get_ylim()[0] * (1 - n), ax.get_ylim()[1] * (1 + n))\n",
    "        ax.set_xlim(ax.get_xlim()[0] * (1 - m), ax.get_xlim()[1] * (1 + m))\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_xticklabels('')\n",
    "        ax.set_yticklabels('')\n",
    "        plt.tick_params(bottom = False, left=False)\n",
    "        plt.title(rubric)\n",
    "\n",
    "        for xi, yi, rubric, size in zip(x, y, x.index, sizes):\n",
    "            rs = rubric.split(' ')\n",
    "            if len(rs) > 1:\n",
    "                rsl = len(rs) // 2\n",
    "                rubric = ' '.join(rs[:rsl] + ['\\n'] + rs[rsl:])\n",
    "\n",
    "            shar_path = [r\"C:\\Users\\Mamed\\YandexDisk\\_Documents\\Проекты\\2ГИС 2023\\Лого\\Шар_{:02}.png\".format(shar_num)]\n",
    "            shar_img = OffsetImage(plt.imread(shar_path[0], format=\"png\"), zoom=size)\n",
    "            ab = AnnotationBbox(shar_img, (xi, yi), frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "            plt.annotate(rubric, (xi, yi), ha='center', va='center', font=fpath, color='#404040')\n",
    "\n",
    "        ax.hlines((y.min()+y.max())/2, x.min(), x.max(), colors='gray', linewidth=1)\n",
    "        ax.vlines((x.min()+x.max())/2, y.min(), y.max(), colors='gray', linewidth=1)\n",
    "        \n",
    "        im = plt.imread(r\"C:\\Users\\Mamed\\YandexDisk\\_Documents\\Проекты\\2ГИС 2023\\Лого\\лого_шт_232_354_gray.png\")\n",
    "        newax = fig.add_axes([0.1, 0.8, 0.1, 0.1], zorder=1, alpha=0.5)\n",
    "        newax.imshow(im)\n",
    "        newax.axis('off')\n",
    "        im = plt.imread(r\"C:\\Users\\Mamed\\YandexDisk\\_Documents\\Проекты\\2ГИС 2023\\Лого\\лого_2гис_232_354_gray.png\")\n",
    "        newax = fig.add_axes([0.9, 0.1, 0.1, 0.1], zorder=1, alpha=0.5)\n",
    "        newax.imshow(im)\n",
    "        newax.axis('off')\n",
    "        fig.savefig(f'pictures/{city}_shar_{shar_num}.png', bbox_inches='tight', transparent=True)\n",
    "        \n",
    "        txt = ''\n",
    "        for cat in ['Звёзды:','Коровы:','Дети:','Собаки:']:\n",
    "            txt +=  cat + ' ' + ', '.join([word[::-1].replace('/', 'и', 1)[::-1].replace('/', ',').replace(' ,', ',') for word in df[df['group'] == cat].index]) + \"\\n\"\n",
    "        txt = txt[::-1].replace('\\n',':', 1)[::-1]\n",
    "        add_image(f'files/{city}/{city}_shars_{time}.docx', f'pictures/{city}_shar_{shar_num}.png', word=txt)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b376d81-1480-4f74-99ff-ec46c69a7ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-22T14:20:56.288790Z",
     "iopub.status.busy": "2023-04-22T14:20:56.288790Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files/ten_city/ten_city_shars_230422_1720.docx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▋                                                                            | 7/100 [00:24<06:18,  4.07s/it]"
     ]
    }
   ],
   "source": [
    "plot_matrix_cities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d754a-8137-44cd-b15f-729f93976a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
