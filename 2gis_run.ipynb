{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c7cc2d1-be00-4944-8a7c-15da77ca9c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready: 2023-04-02 23:41:31\n"
     ]
    }
   ],
   "source": [
    "%run 2gis_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f11c4e-6a5f-4e80-b110-f7aec1f2079d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark_Tutorial</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x243749a4b20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('PySpark_Tutorial')\\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29e59992-0884-4c32-929a-bb2429f945d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@show_time\n",
    "def count_users_requests(file_path):\n",
    "    year = file_path.split('_')[-2]\n",
    "    requests_name = f'Запросы {year}'\n",
    "    users_name = f'Пользователи {year}'\n",
    "    df = dd.read_csv(file_path, dtype={'user': 'object'}, on_bad_lines='skip')[['user', 'rubricName', 'date']]\n",
    "    cnt_user_grouped = df.groupby('rubricName').user.nunique().to_frame()\n",
    "    cnt_req_grouped = df.groupby('rubricName').date.count().to_frame()\n",
    "    user_cnt_year = df.user.nunique().compute()\n",
    "    print(year, user_cnt_year)\n",
    "    cnt_user_grouped_year = (cnt_req_grouped\n",
    "                  .merge(cnt_user_grouped, left_on='rubricName', right_on='rubricName')\n",
    "                  .rename(columns={'date':requests_name, 'user':users_name})\n",
    "                  .sort_values(requests_name, ascending=False)\n",
    "                  .fillna(0)\n",
    "                  .astype(int)\n",
    "                  )\n",
    "    return cnt_user_grouped_year\n",
    "\n",
    "@show_time\n",
    "def count_total_users(*files):\n",
    "    df_list = [dd.read_csv(file_path, dtype={'user': 'object'}, on_bad_lines='skip')[['rubricName', 'user']] for file_path in files]\n",
    "    df_all = dd.concat(df_list)\n",
    "    cnt_user_grouped_total = df_all.groupby('rubricName').user.nunique().to_frame().rename(columns={'user':'Пользователи, итого'})\n",
    "    cnt_user_total = df_all.user.nunique().compute()\n",
    "    print(cnt_user_total)\n",
    "    return cnt_user_grouped_total\n",
    "\n",
    "@show_time\n",
    "def make_base_counted_file(*files):\n",
    "    df = count_users_requests(files[0])\n",
    "    df.to_csv(f'{files[0]}_count_users_requests.csv', single_file=True)\n",
    "    for file in files[1:]:\n",
    "        df = df.merge(count_users_requests(file), left_on='rubricName', right_on='rubricName')\n",
    "        df.to_csv(f'{file}_count_users_requests.csv', single_file=True)\n",
    "        \n",
    "    df = df.merge(count_total_users(files), left_on='rubricName', right_on='rubricName')\n",
    "    df.to_csv('{}_count_total_users.csv'.format(file.split(\"\\\\\")[-2]), single_file=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "@show_time\n",
    "def count_users_requests(file_path):\n",
    "    try:\n",
    "        cnt_user_grouped_year = dd.read_csv(f'{file_path}_count_users_requests.csv')\n",
    "        print('read ' + f'{file_path}_count_users_requests.csv')\n",
    "    except:\n",
    "        year = file_path.split('_')[-2]\n",
    "        requests_name = f'Запросы {year}'\n",
    "        users_name = f'Пользователи {year}'\n",
    "        df = dd.read_csv(file_path, dtype={'user': 'object'}, on_bad_lines='skip')[['user', 'rubricName', 'date']]\n",
    "        cnt_user_grouped = df.groupby('rubricName').user.nunique().to_frame()\n",
    "        cnt_req_grouped = df.groupby('rubricName').date.count().to_frame()\n",
    "        #user_cnt_year = df.user.nunique().compute()\n",
    "        #print(year, user_cnt_year)\n",
    "        cnt_user_grouped_year = (cnt_req_grouped\n",
    "                      .merge(cnt_user_grouped, left_on='rubricName', right_on='rubricName')\n",
    "                      .rename(columns={'date':requests_name, 'user':users_name})\n",
    "                      .sort_values(requests_name, ascending=False)\n",
    "                      .fillna(0)\n",
    "                      .astype(int)\n",
    "                      )\n",
    "        cnt_user_grouped_year.to_csv(f'{file_path}_count_users_requests.csv', single_file=True)\n",
    "    finally:\n",
    "        df = dd.read_csv(f'{file_path}_count_users_requests.csv')\n",
    "    return df\n",
    "\n",
    "@show_time\n",
    "def count_total_users(*files):\n",
    "    file_path = \"\\\\\".join(files[0][0].split(\"\\\\\")[:-1]) + \"\\\\\" + files[0][0].split(\"\\\\\")[-2]\n",
    "    try:\n",
    "        cnt_user_grouped_total = dd.read_csv(\"{}_count_total_users.csv\".format(file_path))\n",
    "        print('read ' + \"{}_count_total_users.csv\".format(file_path))\n",
    "    except:\n",
    "        df_list = [dd.read_csv(file_path, dtype={'user': 'object'}, on_bad_lines='skip')[['rubricName', 'user']] for file_path in files]\n",
    "        df_all = dd.concat(df_list)\n",
    "        cnt_user_grouped_total = df_all.groupby('rubricName').user.nunique().to_frame().rename(columns={'user':'Пользователи, итого'})\n",
    "        #cnt_user_total = df_all.user.nunique().compute()\n",
    "        #print(cnt_user_total)\n",
    "        cnt_user_grouped_total.to_csv(f'{file_path}_count_total_users.csv', single_file=True)\n",
    "    finally:\n",
    "        df = dd.read_csv(\"{}_count_total_users.csv\".format(file_path))\n",
    "    return df\n",
    "\n",
    "@show_time\n",
    "def make_base_counted_file(*files):\n",
    "    df = count_users_requests(files[0])\n",
    "    for file in files[1:]:\n",
    "        df = df.merge(count_users_requests(file), left_on='rubricName', right_on='rubricName', how='outer')\n",
    "    df = df.merge(count_total_users(files), left_on='rubricName', right_on='rubricName', how='outer')\n",
    "    df.to_csv('master_file.csv', single_file=True)\n",
    "    return df\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae3b33-2905-43e6-8425-ea991af6a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 11m 42s\n",
      "[########################################] | 100% Completed | 11m 42s\n",
      "[########################################] | 100% Completed | 11m 42s\n",
      "Start:     2023-04-02 23:41:37\n",
      "End:       2023-04-02 23:53:20\n",
      "Duration:  0:11:42\n",
      "[########################################] | 100% Completed | 11m 41s\n",
      "[########################################] | 100% Completed | 11m 41s\n",
      "[########################################] | 100% Completed | 11m 41s\n",
      "Start:     2023-04-02 23:53:20\n",
      "End:       2023-04-03 00:05:01\n",
      "Duration:  0:11:41\n",
      "[########################################] | 100% Completed | 15m 58s\n",
      "[########################################] | 100% Completed | 15m 58s\n",
      "[########################################] | 100% Completed | 15m 58s\n",
      "Start:     2023-04-03 00:05:01\n",
      "End:       2023-04-03 00:21:00\n",
      "Duration:  0:15:58\n",
      "[########################################] | 100% Completed | 25m 19s\n",
      "[########################################] | 100% Completed | 25m 20s\n",
      "[########################################] | 100% Completed | 25m 20s\n",
      "Start:     2023-04-03 00:21:00\n",
      "End:       2023-04-03 00:46:20\n",
      "Duration:  0:25:20\n",
      "[####################                    ] | 51% Completed | 31m 29ss"
     ]
    }
   ],
   "source": [
    "x = make_base_counted_file(\n",
    "\"D:\\файлы_2гис_2023\\Астана\\Астана_2020_975007.csv\",\n",
    "\"D:\\файлы_2гис_2023\\Астана\\Астана_2021_975009.csv\",\n",
    "\"D:\\файлы_2гис_2023\\Астана\\Астана_2022_975011.csv\",\n",
    "\"D:\\файлы_2гис_2023\\Астана\\Астана_2023_975039.csv\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fc8b2-77db-4f0c-826c-9acd970433df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
